{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08e09d48",
   "metadata": {},
   "source": [
    "# BERT based NER using CoNLL-2003\n",
    "> Author: Xin Xu <xxucs@zju.edu.cn>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14365b62",
   "metadata": {},
   "source": [
    "## Overview\n",
    "- **Named-entity recognition (NER)** (also known as named entity identification, entity chunking, and entity extraction) is a subtask of information extraction that seeks to locate and classify named entities mentioned in unstructured text into pre-defined categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc.\n",
    "- [**CoNLL-2003**](https://www.clips.uantwerpen.be/conll2003/ner/) is a dataset for NER, concentrating on four types of named entities related to persons, locations, organizations, and names of miscellaneous entities. The dataset is in 'data' folder, containing *train.txt*, *valid.txt* and *test.txt*\n",
    "- [**Bidirectional Encoder Representations from Transformers (BERT)**](https://github.com/google-research/bert) is a transformer-based machine learning technique for natural language processing (NLP) pre-training developed by Google."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733b418c",
   "metadata": {},
   "source": [
    "## Clone Repository\n",
    "The 1st step is to clone DeepKE Github Repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65822b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/xxupiano/BERTNER.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6b8798",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd BERTNER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b0cf3f",
   "metadata": {},
   "source": [
    "## Prepare the runtime environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e46f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2319dc",
   "metadata": {},
   "source": [
    "## Fine-Tune\n",
    "- Finetune or train the **bert-base** model run the 'run_ner.py'\n",
    "- In below command we have to pass different arguments:\n",
    "  - '--data_dir' argument required to collect dataset. Pass 'data/' as argument which we can see as directory inside 'BERT-NER' folder for the previous comment and command for 'BERT-NER files'.\n",
    "  - '--bert_model' used to download pretrained bert base model of Hugging Face transformers. There are different model-names as suggested by hugging face for argument, here we select 'bert-base-cased'.\n",
    "  - '--task_name' argument used for task to perform. Enter 'ner' as we will train the model for Named Entity Recogintion(NER).\n",
    "  - '--output_dir' argument is for where to store fine-tuned model. We give name 'out_base' for directory where fine-tuned model stored.\n",
    "  - Other arguments like '--max_seq_length', '--num_train_epochs' and '--warmup_proportion', just give values as suggested in repository.\n",
    "  - For training pass argument '--do_train' and after that evaluating for results pass argument '--do_eval'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdd7e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_ner.py --data_dir=data/ --bert_model=bert-base-cased --task_name=ner --output_dir=out_ner --max_seq_length=128 --do_train --num_train_epochs 5 --do_eval --warmup_proportion=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0f79a8",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "- Set the variable *text* in the following cell as the sentence to be NERed\n",
    "- Run the following cell to get the NER result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da6a2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert import Ner\n",
    "model = Ner(\"out_ner/\")\n",
    "\n",
    "text= \"Irene, a master student in Zhejiang University, Hangzhou, is traveling in Warsaw for Chopin Music Festival.\"\n",
    "print(\"Text to predict Entity:\")\n",
    "print(text)\n",
    "print('Results of NER:')\n",
    "\n",
    "result = model.predict(text)\n",
    "for k,v in result.items():\n",
    "    if v:\n",
    "        print(v,end=': ')\n",
    "        if k=='PER':\n",
    "            print('Person')\n",
    "        elif k=='LOC':\n",
    "            print('Location')\n",
    "        elif k=='ORG':\n",
    "            print('Organization')\n",
    "        elif k=='MISC':\n",
    "            print('Miscellaneous')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
